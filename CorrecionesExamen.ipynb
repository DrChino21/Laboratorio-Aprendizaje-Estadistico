{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a72b3f1",
   "metadata": {},
   "source": [
    "# Examen 1 : Regresión - Correción\n",
    "\n",
    "André Esteban Vera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40299f9f",
   "metadata": {},
   "source": [
    "## Parte Teórica\n",
    "\n",
    "**1.¿Qué es un pipeline (flujo de pasos)?**\n",
    "\n",
    "Un *pipeline* es básicamente una serie o cadena de pasos que se ejecutan en orden para automatizar un proceso. \n",
    "Nos ayuda a conectar desde la limpieza y preparación de la información hasta \n",
    "la construcción y evaluación de un modelo, todo dentro de una misma estructura.\n",
    "\n",
    "**2.¿Cuál es el propósito de realizar regresiones? Explica las ventajas y desventajas de los dos planteamientos vistos en clase.**\n",
    "\n",
    "La regresión busca entender y predecir cómo se relacionan las variables independientes (X) con la \n",
    "dependiente (Y).  \n",
    "- **Sin penalización:** sencillo de interpretar, porque cada coeficiente refleja directamente el impacto de la variable. \n",
    "La parte negativa es que puede sobreajustarse y ser sensible al ruido.  \n",
    "- **Con penalización:** ayuda a estabilizar los coeficientes, controlar la multicolinealidad y evitar sobreajuste. \n",
    "Lo malo es que interpretar los coeficientes ya no es tan directo y, a veces, se pierde algo de precisión.\n",
    "\n",
    "**3.¿En qué consiste el proceso de escalamiento de factores?**\n",
    "\n",
    "Es poner todas las variables en la misma escala, de forma que ninguna domine al modelo solo por tener valores numéricos más grandes.\n",
    "\n",
    "**4.Explica el propósito de penalizar factores en una regresión.**\n",
    "\n",
    "Se hace para que el modelo sea menos complejo y evite memorizar demasiado los datos de entrenamiento. \n",
    "La penalización castiga los valores grandes de los coeficientes (ya sea con cuadrados o valores absolutos).\n",
    "\n",
    "**5.¿Cuál es la relación entre escalamiento y penalización?**\n",
    "\n",
    "Si no escalamos antes, las penalizaciones tratarían de forma injusta a las variables de mayor magnitud. \n",
    "Por eso el escalamiento es un paso previo funadamental y necesario.\n",
    "\n",
    "**6.Explica el concepto de una prueba de hipótesis.**\n",
    "\n",
    "Es un procedimiento para evaluar, con datos de una muestra, si una afirmación sobre la población tiene sentido o no. \n",
    "Se plantean dos hipótesis (nula y alternativa) y, según la evidencia, decidimos si rechazamos la nula.\n",
    "\n",
    "**7.Explica la interpretación de un p-value de una prueba de hipótesis que compara contra una media µ.**\n",
    "\n",
    "El *p-value* nos dice qué tan raro sería obtener los datos si en realidad la hipótesis nula fuera cierta.  \n",
    "Si el valor es menor al nivel de significancia, se rechaza H0. Ejemplo: al comparar la media de una muestra contra µ=50, \n",
    "si el p-value=0.01, significa que habría solo un 1% de probabilidad de ver esos datos si la media real fuera 50.\n",
    "\n",
    "**8.Describe el propósito de realizar cross-validation.**\n",
    "\n",
    "Sirve para comprobar qué tan bien generaliza un modelo. Dividimos los datos en varios subconjuntos, \n",
    "entrenamos y probamos en diferentes combinaciones, lo que reduce el riesgo de sobreajuste.\n",
    "\n",
    "**9.Describe los pasos que seguirías al hacer un análisis exploratorio de datos. Justifica cada paso.**\n",
    "\n",
    "los pasos del EDA son:\n",
    "1. Cargar los datos y limpiarlos (nulos, duplicados, inconsistencias).  \n",
    "2. Revisar qué tipo de variables tenemos (categóricas, numéricas, fechas).  \n",
    "3. Obtener estadísticas descriptivas y detectar posibles outliers.  \n",
    "4. Transformar variables si hace falta (crear *dummies*, escalar, etc.).  \n",
    "\n",
    "**10.¿Qué es el teorema del límite central?**\n",
    "\n",
    "El TLC dice que, aunque la población tenga cualquier distribución, si tomamos muchas muestras grandes \n",
    "y calculamos sus medias, la distribución de esas medias tenderá a una normal conforme el tamaño de la \n",
    "muestra crezca.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0759fe32",
   "metadata": {},
   "source": [
    "En esta parte anterior la verdad no supe exactamente cuales fueron mis errores aparte de la 2 y 7 que fueron en las únicas donde se me hizo comentario así que decidí hacer todas casi desde cero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f36cbb9",
   "metadata": {},
   "source": [
    "## 1) Preparación de datos\n",
    "\n",
    "- Quitamos duplicados y nulos para evitar sesgos y errores en métricas.\n",
    "- Documentamos cada transformación para que sea reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8832bf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Series_Title</th>\n",
       "      <th>Released_Year</th>\n",
       "      <th>Certificate</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>IMDB_Rating</th>\n",
       "      <th>Meta_score</th>\n",
       "      <th>Director</th>\n",
       "      <th>Gross</th>\n",
       "      <th>Drama</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Family</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>War</th>\n",
       "      <th>Music</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Sport</th>\n",
       "      <th>History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>A</td>\n",
       "      <td>142 min</td>\n",
       "      <td>9.3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>28,341,469</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>A</td>\n",
       "      <td>175 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>134,966,411</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>UA</td>\n",
       "      <td>152 min</td>\n",
       "      <td>9.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>534,858,444</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>A</td>\n",
       "      <td>202 min</td>\n",
       "      <td>9.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>57,300,000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>U</td>\n",
       "      <td>96 min</td>\n",
       "      <td>9.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>Sidney Lumet</td>\n",
       "      <td>4,360,000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              Series_Title Released_Year Certificate  Runtime  \\\n",
       "0           0  The Shawshank Redemption          1994           A  142 min   \n",
       "1           1             The Godfather          1972           A  175 min   \n",
       "2           2           The Dark Knight          2008          UA  152 min   \n",
       "3           3    The Godfather: Part II          1974           A  202 min   \n",
       "4           4              12 Angry Men          1957           U   96 min   \n",
       "\n",
       "   IMDB_Rating  Meta_score              Director        Gross  Drama  ...  \\\n",
       "0          9.3        80.0        Frank Darabont   28,341,469      1  ...   \n",
       "1          9.2       100.0  Francis Ford Coppola  134,966,411      1  ...   \n",
       "2          9.0        84.0     Christopher Nolan  534,858,444      1  ...   \n",
       "3          9.0        90.0  Francis Ford Coppola   57,300,000      1  ...   \n",
       "4          9.0        96.0          Sidney Lumet    4,360,000      1  ...   \n",
       "\n",
       "   Fantasy  Family  Thriller  Romance  Sci-Fi  War  Music  Musical  Sport  \\\n",
       "0        0       0         0        0       0    0      0        0      0   \n",
       "1        0       0         0        0       0    0      0        0      0   \n",
       "2        0       0         0        0       0    0      0        0      0   \n",
       "3        0       0         0        0       0    0      0        0      0   \n",
       "4        0       0         0        0       0    0      0        0      0   \n",
       "\n",
       "   History  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga de datos\n",
    "import pandas as pd\n",
    "datos = pd.read_csv('imdb_top1000_lae.csv')\n",
    "datos.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d831b22e",
   "metadata": {},
   "source": [
    "### Limpieza base\n",
    "Quitamos duplicados y filas con valores faltantes para que las métricas no se distorsionen. Este paso no cambia la distribución de los datos \"buenos\", solo elimina ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4146036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>IMDB_Rating</th>\n",
       "      <th>Meta_score</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Action</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Western</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Family</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>War</th>\n",
       "      <th>Music</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Sport</th>\n",
       "      <th>History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.00000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>518.572829</td>\n",
       "      <td>7.937115</td>\n",
       "      <td>77.158263</td>\n",
       "      <td>0.700280</td>\n",
       "      <td>0.198880</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.123249</td>\n",
       "      <td>0.022409</td>\n",
       "      <td>0.225490</td>\n",
       "      <td>0.228291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077031</td>\n",
       "      <td>0.060224</td>\n",
       "      <td>0.138655</td>\n",
       "      <td>0.123249</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.040616</td>\n",
       "      <td>0.04902</td>\n",
       "      <td>0.015406</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.053221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>295.848106</td>\n",
       "      <td>0.293278</td>\n",
       "      <td>12.401144</td>\n",
       "      <td>0.458456</td>\n",
       "      <td>0.399437</td>\n",
       "      <td>0.397307</td>\n",
       "      <td>0.328954</td>\n",
       "      <td>0.148113</td>\n",
       "      <td>0.418198</td>\n",
       "      <td>0.420026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266827</td>\n",
       "      <td>0.238068</td>\n",
       "      <td>0.345829</td>\n",
       "      <td>0.328954</td>\n",
       "      <td>0.269038</td>\n",
       "      <td>0.197538</td>\n",
       "      <td>0.21606</td>\n",
       "      <td>0.123248</td>\n",
       "      <td>0.152562</td>\n",
       "      <td>0.224632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>262.250000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>526.500000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>777.750000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>997.000000</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  IMDB_Rating  Meta_score       Drama       Crime  \\\n",
       "count  714.000000   714.000000  714.000000  714.000000  714.000000   \n",
       "mean   518.572829     7.937115   77.158263    0.700280    0.198880   \n",
       "std    295.848106     0.293278   12.401144    0.458456    0.399437   \n",
       "min      0.000000     7.600000   28.000000    0.000000    0.000000   \n",
       "25%    262.250000     7.700000   70.000000    0.000000    0.000000   \n",
       "50%    526.500000     7.900000   78.000000    1.000000    0.000000   \n",
       "75%    777.750000     8.100000   86.000000    1.000000    0.000000   \n",
       "max    997.000000     9.300000  100.000000    1.000000    1.000000   \n",
       "\n",
       "           Action   Biography     Western      Comedy   Adventure  ...  \\\n",
       "count  714.000000  714.000000  714.000000  714.000000  714.000000  ...   \n",
       "mean     0.196078    0.123249    0.022409    0.225490    0.228291  ...   \n",
       "std      0.397307    0.328954    0.148113    0.418198    0.420026  ...   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000  ...   \n",
       "\n",
       "          Fantasy      Family    Thriller     Romance      Sci-Fi         War  \\\n",
       "count  714.000000  714.000000  714.000000  714.000000  714.000000  714.000000   \n",
       "mean     0.077031    0.060224    0.138655    0.123249    0.078431    0.040616   \n",
       "std      0.266827    0.238068    0.345829    0.328954    0.269038    0.197538   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "           Music     Musical       Sport     History  \n",
       "count  714.00000  714.000000  714.000000  714.000000  \n",
       "mean     0.04902    0.015406    0.023810    0.053221  \n",
       "std      0.21606    0.123248    0.152562    0.224632  \n",
       "min      0.00000    0.000000    0.000000    0.000000  \n",
       "25%      0.00000    0.000000    0.000000    0.000000  \n",
       "50%      0.00000    0.000000    0.000000    0.000000  \n",
       "75%      0.00000    0.000000    0.000000    0.000000  \n",
       "max      1.00000    1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = datos.drop_duplicates()\n",
    "datos = datos.dropna()\n",
    "datos.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df0df12",
   "metadata": {},
   "source": [
    "### Selección de variables\n",
    "Quitamos columnas que no aportan al modelado o que complican innecesariamente la estructura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f1f7ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Released_Year',\n",
       " 'Runtime',\n",
       " 'IMDB_Rating',\n",
       " 'Meta_score',\n",
       " 'Drama',\n",
       " 'Crime',\n",
       " 'Action',\n",
       " 'Biography',\n",
       " 'Western',\n",
       " 'Comedy']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_a_remover = ['Unnamed: 0','Certificate','Series_Title','Director', 'Gross']\n",
    "datos = datos.drop(columns=cols_a_remover, errors='ignore')\n",
    "list(datos.columns)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07d73f4",
   "metadata": {},
   "source": [
    "## 2) Transformaciones y verificaciones\n",
    "- Estandarizamos el tipo de dato en `Released_Year` (algunas entradas no son año).  \n",
    "- Revisamos estadísticos básicos para detectar valores extremos antes de modelar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07ccb5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Released_Year</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>IMDB_Rating</th>\n",
       "      <th>Meta_score</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Action</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Western</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Family</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>War</th>\n",
       "      <th>Music</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Sport</th>\n",
       "      <th>History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.00000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1995.736325</td>\n",
       "      <td>123.692847</td>\n",
       "      <td>7.937588</td>\n",
       "      <td>77.158485</td>\n",
       "      <td>0.69986</td>\n",
       "      <td>0.199158</td>\n",
       "      <td>0.196353</td>\n",
       "      <td>0.123422</td>\n",
       "      <td>0.022440</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077139</td>\n",
       "      <td>0.060309</td>\n",
       "      <td>0.138850</td>\n",
       "      <td>0.123422</td>\n",
       "      <td>0.078541</td>\n",
       "      <td>0.040673</td>\n",
       "      <td>0.049088</td>\n",
       "      <td>0.015428</td>\n",
       "      <td>0.023843</td>\n",
       "      <td>0.051893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.598222</td>\n",
       "      <td>25.898509</td>\n",
       "      <td>0.293211</td>\n",
       "      <td>12.409849</td>\n",
       "      <td>0.45864</td>\n",
       "      <td>0.399648</td>\n",
       "      <td>0.397518</td>\n",
       "      <td>0.329152</td>\n",
       "      <td>0.148215</td>\n",
       "      <td>0.418406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266999</td>\n",
       "      <td>0.238225</td>\n",
       "      <td>0.346033</td>\n",
       "      <td>0.329152</td>\n",
       "      <td>0.269210</td>\n",
       "      <td>0.197671</td>\n",
       "      <td>0.216204</td>\n",
       "      <td>0.123333</td>\n",
       "      <td>0.152667</td>\n",
       "      <td>0.221968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1930.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1987.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2001.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Released_Year     Runtime  IMDB_Rating  Meta_score      Drama  \\\n",
       "count     713.000000  713.000000   713.000000  713.000000  713.00000   \n",
       "mean     1995.736325  123.692847     7.937588   77.158485    0.69986   \n",
       "std        18.598222   25.898509     0.293211   12.409849    0.45864   \n",
       "min      1930.000000   72.000000     7.600000   28.000000    0.00000   \n",
       "25%      1987.000000  104.000000     7.700000   70.000000    0.00000   \n",
       "50%      2001.000000  120.000000     7.900000   78.000000    1.00000   \n",
       "75%      2010.000000  136.000000     8.100000   86.000000    1.00000   \n",
       "max      2019.000000  238.000000     9.300000  100.000000    1.00000   \n",
       "\n",
       "            Crime      Action   Biography     Western      Comedy  ...  \\\n",
       "count  713.000000  713.000000  713.000000  713.000000  713.000000  ...   \n",
       "mean     0.199158    0.196353    0.123422    0.022440    0.225806  ...   \n",
       "std      0.399648    0.397518    0.329152    0.148215    0.418406  ...   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000  ...   \n",
       "\n",
       "          Fantasy      Family    Thriller     Romance      Sci-Fi         War  \\\n",
       "count  713.000000  713.000000  713.000000  713.000000  713.000000  713.000000   \n",
       "mean     0.077139    0.060309    0.138850    0.123422    0.078541    0.040673   \n",
       "std      0.266999    0.238225    0.346033    0.329152    0.269210    0.197671   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "            Music     Musical       Sport     History  \n",
       "count  713.000000  713.000000  713.000000  713.000000  \n",
       "mean     0.049088    0.015428    0.023843    0.051893  \n",
       "std      0.216204    0.123333    0.152667    0.221968  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    0.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrar entradas no numéricas en Released_Year (por ejemplo, 'PG') y convertir a entero\n",
    "datos = datos[datos['Released_Year'] != 'PG']\n",
    "datos['Released_Year'] = pd.to_numeric(datos['Released_Year'], errors='coerce')\n",
    "datos = datos.dropna(subset=['Released_Year'])\n",
    "datos['Released_Year'] = datos['Released_Year'].astype(int)\n",
    "\n",
    "# Runtime : converimos a int \n",
    "datos['Runtime'] = datos['Runtime'].astype(str).str.replace(' min', '', regex=False)\n",
    "datos['Runtime'] = datos['Runtime'].astype(int)\n",
    "\n",
    "genre_cols = [\n",
    "    'Drama','Crime','Action','Biography','Western','Comedy','Adventure','Animation',\n",
    "    'Horror','Mystery','Film-Noir','Fantasy','Family','Thriller','Romance','Sci-Fi',\n",
    "    'War','Music','Musical','Sport','History'\n",
    "]\n",
    "genre_cols = [c for c in genre_cols if c in datos.columns]\n",
    "\n",
    "for c in genre_cols:\n",
    "    # Cualquier valor no nulo y distinto de 0 lo mapeamos a 1, lo demás a 0\n",
    "    datos[c] = (datos[c].astype(str).str.strip().str.lower().isin(['1','true','yes','y','t']) | (pd.to_numeric(datos[c], errors='coerce') > 0)).astype(int)\n",
    "datos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d21b6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13cd5b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignar variables predictoras y objetivo\n",
    "target_col = 'IMDB_Rating'\n",
    "num_cols = [c for c in ['Released_Year','Runtime','Meta_score'] if c in datos.columns]\n",
    "X_cols = num_cols + genre_cols\n",
    "X = datos[X_cols].copy()\n",
    "y = datos[target_col].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.4, random_state=137)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee02b1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chino\\AppData\\Local\\Temp\\ipykernel_10868\\2702799590.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.48314629 -0.06392043  0.70197297 -0.1186271   0.10019959 -3.23690736\n",
      "  1.08491967  0.81138631 -0.28274711  0.70197297  0.97550633  0.81138631\n",
      "  0.59255963 -1.43158721 -0.99393384 -1.92394725 -0.39216045  0.59255963\n",
      "  0.81138631  0.04549292  0.59255963  0.70197297 -0.22804044  0.31902627\n",
      "  0.42843962 -1.81453391  0.15490626 -0.44686713  0.86609299 -0.17333377\n",
      "  0.48314629  0.37373294  0.86609299  0.2643196  -0.55628047  0.97550633\n",
      "  0.37373294  0.20961293  0.20961293 -0.61098714  0.2643196   1.19433301\n",
      " -0.44686713 -1.48629388  0.04549292  0.59255963  0.31902627 -0.77510715\n",
      " -0.55628047 -3.51044072 -2.63513398  0.48314629  0.2643196  -0.1186271\n",
      " -0.00921376  0.53785296 -1.32217387  0.86609299  0.86609299 -0.00921376\n",
      "  0.92079966  0.6472663   0.37373294 -0.72040048 -0.33745378 -3.12749402\n",
      " -1.37688054 -1.86924058  1.13962634  0.20961293 -3.67456073  0.6472663\n",
      " -0.1186271  -0.39216045 -0.22804044  0.48314629 -1.81453391  0.97550633\n",
      " -0.00921376  0.75667964 -0.72040048 -0.72040048 -2.36160062 -0.55628047\n",
      "  0.04549292  0.2643196   0.92079966  0.97550633  0.53785296  0.37373294\n",
      "  0.92079966 -1.86924058  0.37373294  0.97550633  0.15490626 -0.33745378\n",
      "  1.030213    0.48314629  0.75667964  0.86609299  0.59255963  0.04549292\n",
      "  0.48314629  0.59255963  0.70197297  0.6472663   0.86609299 -0.8845205\n",
      "  1.13962634  1.08491967 -0.44686713  0.92079966 -0.33745378 -0.22804044\n",
      " -0.61098714 -0.5015738  -0.61098714  0.10019959  0.86609299  1.19433301\n",
      " -0.44686713  0.81138631 -1.32217387  0.48314629  1.030213   -0.22804044\n",
      "  1.08491967 -0.17333377 -0.72040048  0.42843962 -2.52572064  0.92079966\n",
      "  0.97550633  0.70197297 -1.10334718  0.20961293  0.04549292  0.86609299\n",
      " -1.32217387  1.030213   -0.17333377  0.31902627 -0.00921376  0.97550633\n",
      "  1.030213    0.10019959  0.2643196  -2.03336059  0.81138631  0.2643196\n",
      "  0.31902627  0.04549292  1.08491967  0.2643196   0.37373294 -0.06392043\n",
      "  0.15490626  0.48314629 -0.17333377  0.86609299  0.53785296  0.92079966\n",
      "  0.42843962  0.42843962 -2.47101396  0.48314629  0.97550633  0.97550633\n",
      " -0.77510715 -1.2674672   0.75667964  0.6472663   1.08491967 -0.93922717\n",
      "  0.59255963 -0.06392043  0.2643196   0.86609299 -1.2674672   0.53785296\n",
      "  0.75667964 -1.43158721  0.53785296  0.10019959  0.6472663   0.2643196\n",
      "  0.86609299 -1.97865392  0.81138631  0.53785296 -1.59570722 -2.79925399\n",
      "  0.04549292  0.42843962  0.92079966  0.37373294  0.75667964  1.13962634\n",
      "  1.13962634  1.19433301 -0.22804044 -0.66569381  0.37373294  1.19433301\n",
      " -2.52572064  0.10019959 -1.32217387 -1.21276052  0.42843962  0.15490626\n",
      "  0.2643196   0.59255963  0.92079966  0.6472663  -0.39216045 -0.99393384\n",
      "  1.030213   -1.15805385  0.81138631 -2.52572064 -0.55628047  0.20961293\n",
      "  0.48314629  0.37373294  0.20961293  0.86609299 -2.52572064 -0.44686713\n",
      "  1.030213   -0.82981382 -2.47101396  0.86609299  1.030213   -0.55628047\n",
      "  0.15490626 -0.22804044  1.030213    0.15490626  0.37373294 -1.92394725\n",
      "  0.92079966  0.2643196   0.92079966 -1.81453391  1.19433301  1.030213\n",
      " -1.21276052 -0.5015738  -0.93922717  0.59255963  0.37373294  0.20961293\n",
      "  0.04549292 -1.48629388  0.20961293  0.31902627  1.030213   -0.39216045\n",
      " -0.44686713 -0.00921376 -0.1186271  -0.55628047  1.08491967 -0.72040048\n",
      "  0.53785296  0.10019959 -1.43158721  0.81138631  0.6472663  -2.03336059\n",
      " -0.00921376  1.19433301 -0.99393384  0.10019959  0.75667964  0.6472663\n",
      "  1.030213    0.6472663  -2.08806726  0.37373294  0.48314629  0.37373294\n",
      "  0.92079966 -0.82981382 -2.08806726]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  X_train_scaled.iloc[:, num_idx] = scaler.fit_transform(X_train.iloc[:, num_idx])\n",
      "C:\\Users\\chino\\AppData\\Local\\Temp\\ipykernel_10868\\2702799590.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.34204693  0.82822169 -0.34204693  0.36011424 -1.74636928 -0.92718124\n",
      " -0.81015438  1.68641868  1.17930227 -0.38105589 -0.38105589 -0.9661902\n",
      " -0.9661902  -0.84916334 -0.10799321  0.32110528 -0.18601112  1.56939181\n",
      " -0.88817229  0.04804261 -0.10799321  0.4771411  -1.23925288  0.20407842\n",
      "  0.04804261 -1.51231555  0.55515901 -0.22502007  2.11551717 -0.92718124\n",
      "  0.51615005 -0.77114543  0.32110528 -0.81015438  0.08705156 -1.00519915\n",
      " -1.78537823 -0.14700216  0.82822169 -0.22502007 -0.42006484  3.24677684\n",
      " -0.88817229  1.80344554 -0.88817229  0.59416796  2.34957089 -1.27826183\n",
      " -0.38105589 -1.00519915 -0.84916334  0.43813215 -0.4590738   2.03749926\n",
      "  0.00903365  1.21831123  0.12606051 -1.16123497  1.06227541 -1.43429765\n",
      "  1.53038286  0.12606051 -0.69312752 -1.04420811  2.46659776  0.16506947\n",
      "  1.9204724   1.80344554  0.39912319  0.71119482  1.02326646  0.59416796\n",
      " -0.18601112 -0.73213647  2.4275888   0.9842575  -1.04420811  0.4771411\n",
      "  0.51615005 -1.00519915  1.33533809 -0.34204693 -0.81015438 -0.73213647\n",
      " -0.81015438  0.12606051  0.00903365  0.63317692 -0.4590738  -0.9661902\n",
      " -0.14700216 -0.26402903 -0.69312752 -0.30303798 -0.49808275 -0.38105589\n",
      "  0.28209633 -0.34204693  1.25732018  0.32110528  0.16506947  1.68641868\n",
      "  0.67218587 -0.4590738  -0.61510961 -1.20024392 -0.42006484 -0.65411857\n",
      "  0.90623959 -0.73213647 -1.66835137 -0.34204693 -1.08321706  2.70065148\n",
      "  0.43813215 -0.84916334  0.16506947 -0.14700216 -0.65411857  0.16506947\n",
      "  0.08705156 -0.42006484 -0.92718124 -0.22502007  0.51615005 -0.9661902\n",
      " -0.42006484  0.63317692  0.59416796  0.32110528 -0.81015438 -0.88817229\n",
      "  0.16506947  0.20407842  0.4771411  -0.9661902  -1.4733066   0.00903365\n",
      "  0.16506947  0.43813215  1.10128436 -0.57610066 -0.38105589 -1.12222601\n",
      " -0.9661902  -1.55132451 -0.22502007 -0.0299753  -0.14700216  0.16506947\n",
      " -1.43429765  1.68641868  0.32110528  0.20407842 -0.88817229  0.39912319\n",
      " -0.9661902  -0.61510961 -1.04420811  2.11551717 -0.57610066  0.51615005\n",
      " -0.14700216  1.21831123 -1.59033346 -0.84916334 -0.18601112 -0.81015438\n",
      "  1.72542763  2.97371416 -0.9661902  -0.26402903 -0.77114543  0.12606051\n",
      "  0.00903365 -0.81015438  2.07650822  0.24308738 -0.77114543 -0.10799321\n",
      " -0.10799321 -0.92718124 -0.14700216 -0.73213647  1.72542763 -0.49808275\n",
      "  1.37434704  0.32110528  1.4913739  -0.14700216  0.90623959 -0.92718124\n",
      " -0.61510961 -0.26402903  0.55515901 -0.42006484  0.55515901  0.16506947\n",
      "  0.32110528  0.24308738  0.32110528 -1.12222601  0.24308738 -0.14700216\n",
      " -0.57610066  1.21831123  0.9842575  -0.06898426 -0.06898426  0.67218587\n",
      "  0.94524855 -0.65411857  0.94524855  1.06227541  1.413356   -1.23925288\n",
      " -0.30303798  0.00903365 -1.23925288 -0.9661902  -1.27826183 -1.31727078\n",
      "  0.12606051  1.02326646  1.02326646  0.16506947 -0.14700216 -0.84916334\n",
      " -0.77114543 -0.49808275 -0.88817229  0.00903365 -0.69312752 -1.08321706\n",
      " -0.14700216  0.71119482  0.82822169 -0.22502007 -0.49808275  3.98794696\n",
      "  0.16506947 -0.34204693 -0.69312752 -1.20024392  1.10128436 -0.73213647\n",
      "  0.28209633  0.24308738 -1.4733066  -0.73213647  0.00903365  0.24308738\n",
      " -0.73213647  0.71119482 -0.77114543 -0.88817229 -0.69312752  2.15452612\n",
      " -0.69312752  0.32110528 -0.77114543  1.06227541  0.16506947 -1.70736032\n",
      "  1.21831123 -1.31727078  2.15452612  0.67218587  0.04804261  1.88146345\n",
      "  2.66164253  2.15452612 -1.31727078 -0.69312752 -1.00519915  1.02326646\n",
      " -0.77114543  0.71119482 -0.18601112 -1.12222601 -0.34204693  0.43813215\n",
      " -1.27826183 -1.27826183  0.59416796]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  X_train_scaled.iloc[:, num_idx] = scaler.fit_transform(X_train.iloc[:, num_idx])\n",
      "C:\\Users\\chino\\AppData\\Local\\Temp\\ipykernel_10868\\2702799590.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.1186271   0.42843962  0.37373294  0.31902627  0.97550633 -0.22804044\n",
      "  0.37373294  0.86609299  0.70197297 -1.37688054  0.04549292  0.86609299\n",
      " -1.43158721 -0.06392043 -0.66569381  0.53785296  0.31902627 -0.28274711\n",
      "  0.75667964 -0.99393384 -0.33745378  0.81138631  1.08491967  0.48314629\n",
      " -0.22804044  0.53785296 -2.36160062  0.86609299 -2.08806726 -1.15805385\n",
      " -0.77510715 -0.66569381  0.92079966  0.70197297  0.97550633  0.20961293\n",
      " -1.43158721  1.19433301  0.92079966 -1.59570722  1.13962634  0.04549292\n",
      "  1.19433301  0.97550633  0.20961293 -1.21276052 -1.37688054  1.08491967\n",
      " -0.06392043  1.08491967 -0.28274711  0.81138631 -0.00921376  0.20961293\n",
      "  0.6472663   0.48314629  0.70197297 -0.22804044  1.19433301 -2.08806726\n",
      "  0.48314629 -0.33745378 -1.59570722  0.81138631  1.030213   -2.03336059\n",
      "  0.97550633  0.37373294 -1.10334718  1.08491967  1.13962634  0.70197297\n",
      " -0.99393384  0.70197297 -0.00921376  0.2643196   0.15490626 -3.01808068\n",
      " -0.66569381 -0.17333377  0.53785296  0.15490626 -0.66569381  0.42843962\n",
      " -0.55628047 -0.8845205  -0.1186271   0.20961293 -3.18220069  0.37373294\n",
      " -0.22804044 -0.06392043 -3.18220069 -1.04864051 -0.33745378 -0.17333377\n",
      "  0.2643196   0.6472663  -0.1186271   0.6472663   0.10019959  0.92079966\n",
      " -3.45573405  0.6472663   0.20961293 -0.17333377 -1.81453391  0.6472663\n",
      " -0.5015738   0.97550633  1.030213   -0.00921376  0.15490626 -0.28274711\n",
      " -0.55628047 -1.65041389 -2.36160062  0.10019959 -2.36160062 -0.61098714\n",
      "  0.48314629  1.19433301 -1.43158721 -1.15805385 -2.14277394  0.70197297\n",
      "  0.37373294  0.10019959  0.6472663  -0.33745378 -2.19748061 -1.65041389\n",
      "  1.08491967  1.030213    1.19433301 -1.32217387 -0.5015738  -0.44686713\n",
      "  0.42843962  0.15490626 -2.03336059 -1.10334718  0.92079966 -1.86924058\n",
      "  0.59255963  0.20961293 -1.54100055  0.97550633  0.53785296 -0.55628047\n",
      " -0.17333377  0.48314629 -2.90866733  1.08491967 -1.32217387 -0.77510715\n",
      "  1.030213   -0.44686713 -0.00921376 -2.41630729  0.10019959  0.92079966\n",
      "  0.53785296  0.75667964  0.59255963 -0.8845205   1.13962634 -1.32217387\n",
      "  0.97550633  0.70197297  0.2643196   0.04549292  0.31902627 -0.66569381\n",
      "  0.6472663   0.53785296 -0.28274711  0.31902627  0.37373294 -0.06392043\n",
      "  0.6472663  -0.55628047  0.59255963 -0.5015738   0.15490626  0.92079966\n",
      "  0.53785296 -0.39216045  0.53785296  0.37373294 -0.72040048  0.31902627\n",
      "  0.92079966 -0.44686713 -0.99393384  0.6472663   0.92079966  0.20961293\n",
      "  0.04549292 -3.61985406  1.13962634 -1.15805385 -0.1186271   0.59255963\n",
      "  0.75667964 -0.39216045  1.08491967  0.20961293  0.92079966 -0.61098714\n",
      " -2.58042731  0.42843962  0.15490626  0.31902627 -0.1186271  -1.75982724\n",
      "  0.92079966 -0.1186271   0.48314629  0.97550633  1.19433301 -0.61098714\n",
      " -3.12749402 -0.39216045 -1.75982724 -0.28274711 -2.14277394  0.70197297\n",
      " -0.33745378 -0.82981382 -1.65041389  0.31902627  1.19433301 -0.28274711\n",
      " -0.28274711  0.2643196   0.37373294  1.08491967 -0.33745378  0.20961293\n",
      " -0.61098714  0.75667964  0.31902627  0.2643196   0.31902627 -0.17333377\n",
      " -1.21276052 -0.17333377 -1.37688054  0.75667964  0.81138631 -0.00921376\n",
      " -0.22804044 -0.55628047 -2.14277394  0.59255963 -0.22804044 -0.99393384\n",
      " -1.54100055 -0.93922717  1.030213    0.20961293  0.31902627  0.86609299\n",
      "  0.10019959 -0.82981382 -3.18220069  1.08491967  0.53785296 -1.48629388\n",
      "  0.10019959 -0.22804044  0.6472663   0.04549292  0.10019959  0.04549292\n",
      " -0.72040048  0.70197297 -1.32217387  0.92079966  0.42843962 -1.97865392\n",
      "  0.75667964 -1.43158721 -0.55628047 -0.22804044 -1.70512057  0.81138631\n",
      "  0.31902627 -0.1186271  -1.32217387  0.20961293 -0.28274711  0.20961293\n",
      " -0.66569381 -2.68984065  0.42843962  1.13962634 -0.82981382 -0.39216045\n",
      " -0.22804044  1.19433301  0.86609299  0.04549292 -3.12749402 -3.07278735\n",
      " -0.82981382  1.13962634 -0.82981382  0.48314629 -0.93922717  0.6472663\n",
      " -0.82981382 -1.04864051  1.030213   -1.92394725 -1.70512057 -0.33745378\n",
      " -0.99393384  0.37373294  0.20961293  0.20961293  0.10019959 -1.15805385\n",
      "  0.59255963  0.2643196   0.6472663   1.08491967  0.81138631  0.86609299\n",
      "  0.97550633  0.59255963  0.6472663  -0.82981382 -1.2674672   0.10019959\n",
      " -0.1186271  -1.2674672   0.37373294 -0.28274711 -2.03336059 -0.33745378\n",
      "  0.53785296 -1.04864051 -0.93922717  1.08491967  0.70197297 -2.19748061\n",
      "  0.53785296 -1.32217387  0.92079966  0.37373294 -1.2674672   0.20961293\n",
      "  0.70197297  0.15490626 -0.06392043  0.48314629  0.15490626  0.31902627\n",
      "  0.92079966  0.92079966 -0.22804044  0.48314629  1.030213    0.6472663\n",
      " -0.00921376  0.48314629  1.030213    0.86609299 -0.99393384 -1.81453391\n",
      " -0.61098714 -0.5015738  -0.82981382  1.030213    0.42843962 -1.81453391\n",
      " -3.3463207  -1.65041389  1.13962634  1.08491967 -0.00921376  0.92079966\n",
      "  0.31902627 -0.72040048 -0.93922717  0.86609299  0.75667964 -1.04864051\n",
      "  1.19433301  0.04549292  0.92079966  0.15490626  0.37373294 -1.75982724\n",
      "  0.42843962  0.2643196  -0.99393384 -0.17333377 -0.22804044  0.92079966\n",
      "  0.37373294  0.53785296  0.53785296  0.70197297 -0.22804044 -2.79925399\n",
      "  0.20961293 -0.66569381  0.31902627 -0.8845205   1.13962634 -0.1186271\n",
      " -0.5015738  -1.54100055 -0.22804044  0.53785296 -1.59570722  0.59255963\n",
      "  0.75667964  0.15490626  0.70197297  0.10019959 -0.1186271  -0.17333377\n",
      "  0.86609299  0.37373294]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  X_test_scaled.iloc[:, num_idx] = scaler.transform(X_test.iloc[:, num_idx])\n",
      "C:\\Users\\chino\\AppData\\Local\\Temp\\ipykernel_10868\\2702799590.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.72542763 -0.06898426 -0.81015438 -1.00519915  1.17930227  0.04804261\n",
      "  0.63317692 -0.10799321  0.78921273 -0.06898426 -0.26402903 -0.34204693\n",
      "  0.39912319  0.12606051  1.413356   -1.16123497 -0.06898426  2.97371416\n",
      "  0.28209633 -0.34204693 -0.5370917   1.53038286 -0.49808275 -1.39528869\n",
      "  0.16506947 -0.42006484 -0.69312752  0.43813215  3.3638037   0.36011424\n",
      "  0.20407842 -1.70736032 -0.26402903 -0.22502007 -0.22502007  0.36011424\n",
      " -0.30303798  0.36011424 -1.04420811  1.53038286 -0.9661902  -0.34204693\n",
      " -1.12222601  0.82822169 -0.0299753  -1.35627974 -0.65411857  0.24308738\n",
      "  0.36011424  1.4913739  -0.22502007  0.04804261 -0.77114543  3.83191115\n",
      "  1.413356   -0.65411857 -0.88817229 -0.26402903 -1.00519915  0.39912319\n",
      "  0.75020378 -1.04420811 -0.81015438 -0.22502007 -0.92718124 -0.65411857\n",
      "  0.71119482 -0.10799321 -0.18601112  0.43813215 -0.30303798 -1.39528869\n",
      " -0.5370917  -0.30303798  1.14029332  0.75020378 -0.4590738  -0.92718124\n",
      " -0.38105589 -0.69312752 -0.84916334  1.10128436  0.24308738  0.39912319\n",
      " -0.84916334  0.90623959 -1.12222601 -0.22502007 -0.92718124  2.58362462\n",
      " -0.30303798 -1.27826183  0.12606051 -1.35627974 -0.30303798  0.63317692\n",
      " -0.26402903 -1.16123497  0.39912319  1.06227541 -0.5370917  -0.18601112\n",
      " -0.81015438 -1.12222601 -0.42006484 -1.4733066   1.72542763 -1.4733066\n",
      "  0.08705156 -1.20024392 -0.30303798  0.32110528 -0.84916334 -0.5370917\n",
      " -0.65411857  0.04804261  3.16875893  0.51615005 -0.5370917  -0.22502007\n",
      "  0.16506947  1.37434704  1.21831123 -0.22502007 -0.69312752 -1.00519915\n",
      " -1.04420811 -0.69312752 -1.51231555 -1.62934242 -1.16123497 -0.61510961\n",
      " -0.84916334  0.75020378  1.02326646 -0.5370917  -1.59033346 -0.14700216\n",
      "  0.71119482 -0.88817229  2.77866939 -1.27826183 -1.00519915 -0.49808275\n",
      "  1.02326646 -0.61510961 -0.49808275  0.28209633 -0.18601112 -0.73213647\n",
      " -0.92718124 -0.9661902  -0.73213647 -1.23925288 -0.92718124  2.62263357\n",
      " -0.06898426  0.04804261  0.4771411  -0.30303798 -0.49808275  1.68641868\n",
      "  0.55515901 -1.00519915 -0.14700216 -1.16123497 -0.34204693 -0.14700216\n",
      " -0.69312752  0.86723064  0.59416796 -1.27826183  0.67218587  1.10128436\n",
      "  0.08705156 -0.42006484 -1.39528869 -1.39528869 -1.04420811 -1.08321706\n",
      "  0.12606051  1.45236495 -1.08321706  0.28209633 -0.49808275 -0.77114543\n",
      " -1.00519915 -0.81015438  0.86723064 -1.4733066  -0.81015438 -0.9661902\n",
      "  0.00903365 -1.20024392 -1.20024392 -1.00519915  0.39912319 -0.06898426\n",
      " -1.74636928 -1.51231555 -0.26402903  0.4771411  -0.9661902  -0.22502007\n",
      " -0.22502007 -0.88817229 -0.9661902  -1.04420811 -0.4590738  -0.73213647\n",
      "  0.4771411   0.12606051 -0.61510961  2.03749926  0.04804261  1.80344554\n",
      "  0.24308738  2.03749926 -0.61510961  0.12606051 -0.69312752 -1.43429765\n",
      " -0.0299753  -0.42006484  0.24308738  0.4771411   0.08705156 -1.08321706\n",
      "  0.16506947  2.4275888  -0.77114543 -1.27826183 -0.26402903 -1.00519915\n",
      "  0.16506947 -0.5370917  -0.18601112 -0.49808275  0.43813215 -1.39528869\n",
      " -0.88817229  0.20407842 -0.0299753  -0.65411857 -0.92718124 -1.31727078\n",
      " -0.0299753  -1.31727078 -0.92718124 -0.5370917   0.67218587  0.04804261\n",
      " -0.0299753  -1.62934242 -1.20024392 -1.23925288 -0.18601112  0.82822169\n",
      " -0.61510961 -0.06898426  0.08705156 -1.08321706 -0.18601112 -0.84916334\n",
      "  2.4275888   2.54461566  4.3780365   0.39912319 -0.14700216 -0.49808275\n",
      " -0.9661902  -0.92718124  1.14029332 -0.30303798  0.39912319 -1.00519915\n",
      " -0.73213647 -1.23925288 -0.4590738   0.90623959 -1.23925288 -1.00519915\n",
      "  0.78921273 -1.00519915 -0.26402903 -0.9661902  -0.22502007  0.04804261\n",
      " -1.78537823  0.12606051 -2.09744986 -1.20024392 -1.04420811  2.03749926\n",
      " -1.12222601  0.00903365 -0.38105589 -0.18601112  0.12606051  0.78921273\n",
      "  2.11551717 -0.14700216 -1.35627974 -1.78537823  0.12606051 -0.26402903\n",
      " -0.65411857  0.00903365 -0.65411857 -0.30303798  0.28209633  1.413356\n",
      " -1.20024392  2.23254403 -0.9661902   2.03749926  1.37434704 -0.30303798\n",
      " -1.16123497 -0.26402903 -0.49808275 -0.14700216  2.46659776 -0.4590738\n",
      " -0.38105589 -0.9661902  -0.5370917  -0.88817229 -0.65411857  0.16506947\n",
      "  1.64740972 -0.06898426 -1.00519915 -0.42006484 -0.49808275 -1.43429765\n",
      "  0.08705156 -1.27826183  0.55515901 -1.59033346  0.08705156  0.12606051\n",
      "  0.04804261 -0.18601112 -0.06898426 -0.57610066  1.53038286  1.37434704\n",
      " -0.5370917   0.67218587 -0.92718124  1.17930227  0.16506947  0.20407842\n",
      " -0.30303798  1.14029332  1.29632913  0.59416796 -0.92718124  1.10128436\n",
      " -0.92718124 -0.49808275  0.28209633  0.71119482 -1.00519915  0.12606051\n",
      "  0.12606051 -0.10799321 -0.38105589 -0.10799321 -0.81015438 -0.61510961\n",
      " -0.73213647 -1.55132451 -0.34204693  0.04804261  0.55515901  0.51615005\n",
      " -1.51231555 -1.86339614 -0.92718124  0.04804261  0.00903365  0.12606051\n",
      "  2.9347052   0.75020378  0.78921273 -1.08321706 -1.16123497  0.04804261\n",
      "  0.43813215  1.72542763 -0.10799321 -0.73213647  0.28209633  2.77866939\n",
      "  0.24308738  0.36011424  0.16506947  0.04804261 -0.49808275 -1.55132451\n",
      " -0.5370917   1.25732018  1.06227541 -0.69312752  0.16506947  1.72542763\n",
      " -0.38105589 -0.4590738   0.4771411  -0.42006484  0.82822169 -1.74636928\n",
      "  1.14029332  0.75020378 -1.94141405 -1.55132451 -0.5370917  -1.39528869\n",
      "  0.16506947 -1.08321706 -1.20024392  0.78921273 -1.66835137 -0.61510961\n",
      "  0.20407842  0.78921273]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  X_test_scaled.iloc[:, num_idx] = scaler.transform(X_test.iloc[:, num_idx])\n"
     ]
    }
   ],
   "source": [
    "# Escalamiento SOLO a numéricas; los géneros ya son 0/1\n",
    "num_idx = [i for i, c in enumerate(X.columns) if c in num_cols]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Copias para escalamiento\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled  = X_test.copy()\n",
    "\n",
    "# Ajuste/transform a numéricas\n",
    "X_train_scaled.iloc[:, num_idx] = scaler.fit_transform(X_train.iloc[:, num_idx])\n",
    "X_test_scaled.iloc[:, num_idx] = scaler.transform(X_test.iloc[:, num_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4aeb5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión lineal (sin penalización) y p-values\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Tamaños\n",
    "n, p = X_train_scaled.shape\n",
    "\n",
    "# Predicciones y R2\n",
    "y_hat_train = lr.predict(X_train_scaled)\n",
    "R2_train = r2_score(y_train, y_hat_train)\n",
    "\n",
    "y_hat_test = lr.predict(X_test_scaled)\n",
    "R2_test = r2_score(y_test, y_hat_test)\n",
    "\n",
    "# RSS y RSE (en train)\n",
    "RSS = np.sum((y_train - y_hat_train)**2)\n",
    "RSE = np.sqrt(RSS / (n - p - 1))\n",
    "\n",
    "# Varianzas de beta (X incluye intercepto)\n",
    "X_design = np.column_stack([np.ones(n), X_train_scaled.values])\n",
    "XtX_inv = np.linalg.pinv(X_design.T @ X_design)\n",
    "var_beta = XtX_inv * (RSE**2)\n",
    "std_beta = np.sqrt(np.diag(var_beta))\n",
    "\n",
    "# t-stats y p-values bilaterales\n",
    "beta = np.r_[lr.intercept_, lr.coef_]\n",
    "t_values = beta / std_beta\n",
    "dfree = n - p - 1\n",
    "p_values = 2 * (1 - stats.t.cdf(np.abs(t_values), df=dfree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99b84dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Resultados de la regresión sin penalización\n",
      "Intercepto: 8.086293260607736\n",
      "Columnas en X (orden): ['Released_Year', 'Runtime', 'Meta_score', 'Drama', 'Crime', 'Action', 'Biography', 'Western', 'Comedy', 'Adventure', 'Animation', 'Horror', 'Mystery', 'Film-Noir', 'Fantasy', 'Family', 'Thriller', 'Romance', 'Sci-Fi', 'War', 'Music', 'Musical', 'Sport', 'History']\n",
      "Coeficientes: [-0.02491257  0.10947437  0.08278779 -0.08783343 -0.02349929 -0.06416897\n",
      " -0.1170211  -0.08695303 -0.03068953 -0.0811902   0.05331447 -0.18043209\n",
      " -0.04768065 -0.04014471 -0.10320695 -0.06728095 -0.03929    -0.07610397\n",
      " -0.02258708  0.01335441  0.01687677 -0.09431525  0.06706191 -0.06154042]\n",
      "P-values (orden: [Intercepto] + columnas en X): [0.00000000e+00 1.89319514e-01 1.19046406e-08 2.72850021e-06\n",
      " 1.29134879e-01 6.18527557e-01 2.39808794e-01 3.56220861e-02\n",
      " 4.96609870e-01 5.36687839e-01 1.57532985e-01 4.87374451e-01\n",
      " 1.36002780e-01 4.33571256e-01 7.85031334e-01 1.65437965e-01\n",
      " 4.65551318e-01 4.53614935e-01 1.56311240e-01 7.58719992e-01\n",
      " 8.90531699e-01 8.25830709e-01 4.87023895e-01 4.57926863e-01\n",
      " 4.40271467e-01]\n",
      "R2 (train): 0.23773412348087442\n",
      "R2 (test): 0.0902181249349353\n",
      "GL (n - p - 1): 260\n"
     ]
    }
   ],
   "source": [
    "# Resultados Obtenidos\n",
    "print(\"\\n Resultados de la regresión sin penalización\")\n",
    "print(\"Intercepto:\", lr.intercept_)\n",
    "\n",
    "print(\"Columnas en X (orden):\", X.columns.tolist())\n",
    "\n",
    "# Coeficientes en el mismo orden de las columnas en X\n",
    "print(\"Coeficientes:\", lr.coef_)\n",
    "\n",
    "# P-values:\n",
    "print(\"P-values (orden: [Intercepto] + columnas en X):\", p_values)\n",
    "\n",
    "print(\"R2 (train):\", R2_train)\n",
    "print(\"R2 (test):\", R2_test)\n",
    "print(\"GL (n - p - 1):\", dfree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ffa812e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.1\n",
      "Intercepto: 8.083907964092806\n",
      "Columnas en X (orden): ['Released_Year', 'Runtime', 'Meta_score', 'Drama', 'Crime', 'Action', 'Biography', 'Western', 'Comedy', 'Adventure', 'Animation', 'Horror', 'Mystery', 'Film-Noir', 'Fantasy', 'Family', 'Thriller', 'Romance', 'Sci-Fi', 'War', 'Music', 'Musical', 'Sport', 'History']\n",
      "Coeficientes: [-0.02471733  0.10932155  0.08282448 -0.08664818 -0.02280436 -0.06330282\n",
      " -0.11585437 -0.08450971 -0.029774   -0.08022625  0.05315185 -0.1763795\n",
      " -0.04724628 -0.03785613 -0.10190288 -0.06603951 -0.03868643 -0.07523967\n",
      " -0.02219015  0.01404562  0.01654033 -0.09150941  0.06690096 -0.06069455]\n",
      "R2 (train): 0.2377255815931586\n",
      "R2 (test): 0.09100758887883786\n"
     ]
    }
   ],
   "source": [
    "# Regresión con Penalización L2 Ridge para datos de entrenamiento y prueba\n",
    "ridge = Ridge(alpha=0.1, fit_intercept=True, random_state=42)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_hat_train_ridge = ridge.predict(X_train_scaled)\n",
    "y_hat_test_ridge  = ridge.predict(X_test_scaled)\n",
    "\n",
    "R2_train_ridge = r2_score(y_train, y_hat_train_ridge)\n",
    "R2_test_ridge  = r2_score(y_test,  y_hat_test_ridge)\n",
    "\n",
    "# Resultados Obtenidos\n",
    "print(\"Alpha:\", 0.1)\n",
    "print(\"Intercepto:\", ridge.intercept_)\n",
    "print(\"Columnas en X (orden):\", X.columns.tolist())\n",
    "print(\"Coeficientes:\", ridge.coef_)\n",
    "print(\"R2 (train):\", R2_train_ridge)\n",
    "print(\"R2 (test):\",  R2_test_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3fd9ac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.1\n",
      "Intercepto: 7.931228070175439\n",
      "Columnas en X (orden): ['Released_Year', 'Runtime', 'Meta_score', 'Drama', 'Crime', 'Action', 'Biography', 'Western', 'Comedy', 'Adventure', 'Animation', 'Horror', 'Mystery', 'Film-Noir', 'Fantasy', 'Family', 'Thriller', 'Romance', 'Sci-Fi', 'War', 'Music', 'Musical', 'Sport', 'History']\n",
      "Coeficientes: [-0.  0.  0.  0.  0. -0. -0. -0. -0. -0. -0. -0. -0.  0. -0. -0. -0. -0.\n",
      " -0.  0.  0.  0.  0.  0.]\n",
      "R2 (train): 0.0\n",
      "R2 (test): -0.0013103412373274281\n"
     ]
    }
   ],
   "source": [
    "# Regresión con Penalización L1 Lasso para datos de entrenamiento y prueba\n",
    "lasso = Lasso(alpha=0.1, fit_intercept=True, random_state=42, max_iter=10000)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_hat_train_lasso = lasso.predict(X_train_scaled)\n",
    "y_hat_test_lasso  = lasso.predict(X_test_scaled)\n",
    "\n",
    "R2_train_lasso = r2_score(y_train, y_hat_train_lasso)\n",
    "R2_test_lasso  = r2_score(y_test,  y_hat_test_lasso)\n",
    "\n",
    "# Resultados Obtenidos\n",
    "print(\"Alpha:\", 0.1)\n",
    "print(\"Intercepto:\", lasso.intercept_)\n",
    "print(\"Columnas en X (orden):\", X.columns.tolist())\n",
    "print(\"Coeficientes:\", lasso.coef_)\n",
    "print(\"R2 (train):\", R2_train_lasso)\n",
    "print(\"R2 (test):\",  R2_test_lasso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11789e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparación (Ridge vs Lasso)\n",
      "  modelo  alpha  R2_train   R2_test\n",
      "0  Ridge    0.1  0.237726  0.091008\n",
      "1  Lasso    0.1  0.000000 -0.001310\n"
     ]
    }
   ],
   "source": [
    "# Comparación de modelos\n",
    "comparacion = pd.DataFrame({\n",
    "    \"modelo\": [\"Ridge\", \"Lasso\"],\n",
    "    \"alpha\":  [0.1, 0.1],\n",
    "    \"R2_train\": [R2_train_ridge, R2_train_lasso],\n",
    "    \"R2_test\":  [R2_test_ridge,  R2_test_lasso]\n",
    "})\n",
    "print(\"\\nComparación (Ridge vs Lasso)\")\n",
    "print(comparacion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7874cc89",
   "metadata": {},
   "source": [
    "## Interpretación de resultados\n",
    "\n",
    "- **Regresión lineal sin penalización:**  \n",
    "  - R² en train: **0.2377**  \n",
    "  - R² en test: **0.0902**  \n",
    "  Esto muestra que el modelo explica apenas ~24% de la variabilidad en entrenamiento y apenas ~9% en prueba. Es decir, su **capacidad predictiva es limitada** y su poder de generalización es bajo.  \n",
    "  - Algunos p-values fueron muy significativos (ej. `Meta_score` con 1.19e-08 y `Drama` con 2.7e-06), lo que confirma que estas variables tienen un peso importante en explicar el IMDB Rating.  \n",
    "  - Sin embargo, la mayoría de los géneros presentan p-values altos (mayores a 0.05), lo que significa que **no aportan significativamente** al modelo.  \n",
    "\n",
    "- **Ridge (α = 0.1):**  \n",
    "  - R² en train: **0.2377**  \n",
    "  - R² en test: **0.0910**  \n",
    "  Los resultados prácticamente no mejoran frente a la regresión simple, pero sí logran un pequeño ajuste positivo en el test. Ridge estabiliza los coeficientes (evita que se disparen), pero con este α bajo no se ve un cambio drástico en el poder predictivo.  \n",
    "  - Interpretación: Ridge **no aumenta mucho la precisión**, pero sí controla mejor los coeficientes para dar un modelo más robusto.  \n",
    "\n",
    "- **Lasso (α = 0.1):**  \n",
    "  - R² en train: **0.0000**  \n",
    "  - R² en test: **-0.0013**  \n",
    "  Aquí el modelo prácticamente **no logra explicar nada**. El valor negativo en test indica que el modelo lo hace peor que simplemente usar la media como predicción.  \n",
    "  - Interpretación: con este α, Lasso penalizó en exceso y llevó la mayoría de coeficientes a cero, dejando un modelo demasiado simple que perdió toda capacidad predictiva.  \n",
    "\n",
    "### Conclusión\n",
    "- El mejor resultado se dio con la regresión lineal sin penalización y con Ridge, aunque ambos muestran un poder explicativo bajo (R² < 0.25).  \n",
    "- Las variables que realmente destacan son `Meta_score` y el género `Drama`, por su significancia estadística.  \n",
    "- **Lasso no funcionó bien** en este caso con α = 0.1, porque eliminó demasiadas variables y el modelo se volvió irrelevante.  \n",
    "- En general, los resultados indican que con este dataset y estas variables, el IMDB Rating es difícil de predecir con regresión lineal, y que el **Meta_score y ciertos géneros específicos** son los factores que más peso real tienen.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a7ebe",
   "metadata": {},
   "source": [
    "## 5) Cierre y aprendizajes\n",
    "\n",
    "Al hacer la correón del examen de regresión pude identificar varios puntos clave:\n",
    "\n",
    "- **Preparación de datos:** me quedó claro que no basta con cargar el dataset; fue necesario limpiar duplicados, valores nulos y transformar columnas para que el modelo funcionara correctamente. Este paso evitó errores y sesgos.\n",
    "\n",
    "- **Selección de variables:** aprendí a diferenciar entre variables útiles y las que solo agregan ruido (por ejemplo, títulos de películas o directores). Al quedarme con las más relevantes (año, duración, Meta_score y géneros), el modelo ganó claridad y estabilidad.\n",
    "\n",
    "- **Escalamiento:** entendí la importancia de estandarizar variables numéricas cuando se aplican regresiones con penalización. Esto asegura que todas las variables tengan el mismo peso al momento de calcular coeficientes.\n",
    "\n",
    "- **Modelos de regresión:** comprobé cómo la regresión lineal sin penalización puede sobreajustar, mientras que Ridge y Lasso ayudan a controlar la complejidad. Lasso además fuerza a que algunos coeficientes se vuelvan cero, lo que simplifica la interpretación.\n",
    "\n",
    "- **Interpretación de métricas:** usar R² en train y test me permitió medir la capacidad de generalización y entender si el modelo estaba sobreajustado o no. También reforcé la utilidad de los p-values para evaluar la relevancia estadística de cada variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8358fb4c",
   "metadata": {},
   "source": [
    "Que podemos hacer para mejorar el modelo:\n",
    "\n",
    "**Generar nuevas variables (feature engineering):**  \n",
    "  - Crear interacciones entre géneros (ej. `Drama*Romance`) para capturar combinaciones relevantes.  \n",
    "  - Normalizar o agrupar géneros poco frecuentes para evitar ruido.  \n",
    "  - Incluir transformaciones de `Runtime` (ej. categorizar películas cortas, medias, largas).  \n",
    "\n",
    "- **Cambiar de modelo:**  \n",
    "  Si el objetivo es predecir con mayor precisión, vale la pena probar métodos más flexibles como **Random Forests** o **Gradient Boosting**, que capturan relaciones no lineales.  \n",
    "\n",
    "- **Validación cruzada:**  \n",
    "  Evaluar el modelo con k-fold cross-validation en vez de un solo train/test split. Esto da una visión más estable del rendimiento real.  \n",
    "\n",
    "- **Interpretabilidad:**  \n",
    "  Para modelos lineales, usar gráficos de coeficientes y sus intervalos de confianza para visualizar qué variables aportan más. Esto ayuda a comunicar hallazgos de forma clara.  \n",
    "\n",
    "En resumen: los resultados actuales son un buen punto de partida, pero muestran que el dataset es complejo y que **no basta con regresión lineal simple**. Con penalización adecuada, ingeniería de variables y modelos más flexibles, se puede mejorar la capacidad predictiva y obtener conclusiones más sólidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a4f2e",
   "metadata": {},
   "source": [
    "### Probemos con K-Folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b75bc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge (k-folds)\n",
      "Alpha: 0.1\n",
      "R² por fold: [ 0.10434601  0.06744292  0.17099789 -0.08457293  0.19350266]\n",
      "R² promedio: 0.09034330986752566\n",
      "\n",
      "Lasso (k-folds)\n",
      "Alpha: 0.1\n",
      "R² por fold: [ 0.1358073   0.1148575   0.17898913 -0.04169844  0.18710143]\n",
      "R² promedio: 0.11501138189481157\n"
     ]
    }
   ],
   "source": [
    "# Validación cruzada con k-folds (Ridge y Lasso)\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "import numpy as np\n",
    "\n",
    "# Configuración de los folds\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Ridge con cross-validation\n",
    "alpha_ridge = 0.1\n",
    "ridge = Ridge(alpha=alpha_ridge, fit_intercept=True, random_state=42)\n",
    "\n",
    "scores_ridge = cross_val_score(ridge, X, y, cv=kf, scoring=\"r2\")\n",
    "print(\"Ridge (k-folds)\")\n",
    "print(\"Alpha:\", alpha_ridge)\n",
    "print(\"R² por fold:\", scores_ridge)\n",
    "print(\"R² promedio:\", np.mean(scores_ridge))\n",
    "\n",
    "# Lasso con cross-validation\n",
    "alpha_lasso = 0.1\n",
    "lasso = Lasso(alpha=alpha_lasso, fit_intercept=True, random_state=42, max_iter=10000)\n",
    "\n",
    "scores_lasso = cross_val_score(lasso, X, y, cv=kf, scoring=\"r2\")\n",
    "print(\"\\nLasso (k-folds)\")\n",
    "print(\"Alpha:\", alpha_lasso)\n",
    "print(\"R² por fold:\", scores_lasso)\n",
    "print(\"R² promedio:\", np.mean(scores_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899e9c19",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "- Ambos modelos muestran que el poder explicativo del dataset es limitado (R² promedio < 0.12).  \n",
    "- **Lasso resultó ligeramente mejor** que Ridge en validación cruzada, lo que significa que la penalización que simplifica el modelo ayudó a generalizar un poco mejor.  \n",
    "- Aún así, la variación entre folds (valores negativos y positivos) indica que **la capacidad de predicción es muy baja y dependiente del subconjunto de datos**.  \n",
    "\n",
    "### Aprendizaje clave\n",
    "La validación cruzada confirma que el modelo no es robusto: aunque algunos folds muestran R² ~0.18–0.19, otros caen negativos. Esto refuerza la idea de que **con las variables actuales no basta**, y sería necesario:\n",
    "- **Probar más valores de α** para Ridge y Lasso (buscar un balance).  \n",
    "- **Agregar nuevas variables** o features derivados.  \n",
    "- **Explorar modelos no lineales** (árboles, boosting) que podrían captar mejor relaciones complejas.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
